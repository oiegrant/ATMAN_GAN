{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6957d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 128, 128, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grant\\anaconda3\\envs\\tf-gpu2\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 128)     3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 602,113\n",
      "Trainable params: 602,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 16, 16, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 128, 128, 128)     262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 128, 3)       24579     \n",
      "=================================================================\n",
      "Total params: 1,901,059\n",
      "Trainable params: 1,901,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 128, 128, 3)       1901059   \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 1)                 602113    \n",
      "=================================================================\n",
      "Total params: 2,503,172\n",
      "Trainable params: 1,901,059\n",
      "Non-trainable params: 602,113\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch>1, 1/31, d1=6.617, d2=0.695 g=0.692\n",
      "Epoch>1, 2/31, d1=0.000, d2=0.694 g=0.693\n",
      "Epoch>1, 3/31, d1=0.000, d2=0.693 g=0.694\n",
      "Epoch>1, 4/31, d1=0.000, d2=0.692 g=0.695\n",
      "Epoch>1, 5/31, d1=0.000, d2=0.691 g=0.696\n",
      "Epoch>1, 6/31, d1=0.000, d2=0.690 g=0.698\n",
      "Epoch>1, 7/31, d1=0.000, d2=0.688 g=0.699\n",
      "Epoch>1, 8/31, d1=0.000, d2=0.688 g=0.701\n",
      "Epoch>1, 9/31, d1=0.000, d2=0.689 g=0.700\n",
      "Epoch>1, 10/31, d1=0.000, d2=0.695 g=0.696\n",
      "Epoch>1, 11/31, d1=0.000, d2=0.708 g=0.682\n",
      "Epoch>1, 12/31, d1=0.000, d2=0.735 g=0.663\n",
      "Epoch>1, 13/31, d1=0.000, d2=0.758 g=0.637\n",
      "Epoch>1, 14/31, d1=0.000, d2=0.780 g=0.627\n",
      "Epoch>1, 15/31, d1=0.000, d2=0.782 g=0.632\n",
      "Epoch>1, 16/31, d1=0.000, d2=0.745 g=0.653\n",
      "Epoch>1, 17/31, d1=0.000, d2=0.720 g=0.681\n",
      "Epoch>1, 18/31, d1=0.000, d2=0.692 g=0.712\n",
      "Epoch>1, 19/31, d1=0.633, d2=0.843 g=0.507\n",
      "Epoch>1, 20/31, d1=0.000, d2=0.953 g=0.503\n",
      "Epoch>1, 21/31, d1=0.000, d2=0.914 g=0.523\n",
      "Epoch>1, 22/31, d1=0.000, d2=0.896 g=0.561\n",
      "Epoch>1, 23/31, d1=0.000, d2=0.844 g=0.585\n",
      "Epoch>1, 24/31, d1=0.000, d2=0.808 g=0.602\n",
      "Epoch>1, 25/31, d1=0.000, d2=0.786 g=0.629\n",
      "Epoch>1, 26/31, d1=0.000, d2=0.762 g=0.647\n",
      "Epoch>1, 27/31, d1=0.000, d2=0.738 g=0.661\n",
      "Epoch>1, 28/31, d1=0.000, d2=0.716 g=0.683\n",
      "Epoch>1, 29/31, d1=0.000, d2=0.698 g=0.697\n",
      "Epoch>1, 30/31, d1=0.004, d2=0.696 g=0.700\n",
      "Epoch>1, 31/31, d1=0.007, d2=0.689 g=0.705\n",
      "Epoch>2, 1/31, d1=0.000, d2=0.677 g=0.717\n",
      "Epoch>2, 2/31, d1=0.000, d2=0.672 g=0.731\n",
      "Epoch>2, 3/31, d1=0.030, d2=0.678 g=0.697\n",
      "Epoch>2, 4/31, d1=0.000, d2=0.693 g=0.708\n",
      "Epoch>2, 5/31, d1=0.000, d2=0.675 g=0.727\n",
      "Epoch>2, 6/31, d1=0.000, d2=0.657 g=0.748\n",
      "Epoch>2, 7/31, d1=0.263, d2=0.763 g=0.594\n",
      "Epoch>2, 8/31, d1=0.000, d2=0.824 g=0.592\n",
      "Epoch>2, 9/31, d1=0.000, d2=0.795 g=0.612\n",
      "Epoch>2, 10/31, d1=0.000, d2=0.775 g=0.635\n",
      "Epoch>2, 11/31, d1=0.000, d2=0.757 g=0.651\n",
      "Epoch>2, 12/31, d1=0.000, d2=0.758 g=0.662\n",
      "Epoch>2, 13/31, d1=0.000, d2=0.710 g=0.686\n",
      "Epoch>2, 14/31, d1=0.013, d2=0.699 g=0.703\n",
      "Epoch>2, 15/31, d1=0.000, d2=0.680 g=0.718\n",
      "Epoch>2, 16/31, d1=0.000, d2=0.665 g=0.730\n",
      "Epoch>2, 17/31, d1=0.000, d2=0.694 g=0.718\n",
      "Epoch>2, 18/31, d1=0.000, d2=0.692 g=0.731\n",
      "Epoch>2, 19/31, d1=0.000, d2=0.652 g=0.778\n",
      "Epoch>2, 20/31, d1=0.000, d2=0.607 g=0.827\n",
      "Epoch>2, 21/31, d1=0.000, d2=0.571 g=0.893\n",
      "Epoch>2, 22/31, d1=0.000, d2=0.517 g=0.995\n",
      "Epoch>2, 23/31, d1=0.000, d2=0.445 g=1.159\n",
      "Epoch>2, 24/31, d1=0.273, d2=0.408 g=1.242\n",
      "Epoch>2, 25/31, d1=0.000, d2=0.397 g=1.300\n",
      "Epoch>2, 26/31, d1=0.000, d2=0.379 g=1.429\n",
      "Epoch>2, 27/31, d1=0.000, d2=0.486 g=1.227\n",
      "Epoch>2, 28/31, d1=0.000, d2=0.588 g=1.046\n",
      "Epoch>2, 29/31, d1=0.415, d2=0.837 g=0.540\n",
      "Epoch>2, 30/31, d1=0.000, d2=0.915 g=0.548\n",
      "Epoch>2, 31/31, d1=0.000, d2=0.853 g=0.591\n",
      "Epoch>3, 1/31, d1=0.000, d2=0.791 g=0.643\n",
      "Epoch>3, 2/31, d1=0.000, d2=0.736 g=0.673\n",
      "Epoch>3, 3/31, d1=0.000, d2=0.710 g=0.694\n",
      "Epoch>3, 4/31, d1=0.000, d2=0.674 g=0.725\n",
      "Epoch>3, 5/31, d1=0.000, d2=0.657 g=0.750\n",
      "Epoch>3, 6/31, d1=0.000, d2=0.646 g=0.768\n",
      "Epoch>3, 7/31, d1=0.000, d2=0.618 g=0.787\n",
      "Epoch>3, 8/31, d1=0.000, d2=0.606 g=0.805\n",
      "Epoch>3, 9/31, d1=0.001, d2=0.584 g=0.826\n",
      "Epoch>3, 10/31, d1=0.000, d2=0.564 g=0.856\n",
      "Epoch>3, 11/31, d1=0.000, d2=0.556 g=0.884\n",
      "Epoch>3, 12/31, d1=0.735, d2=0.886 g=0.431\n",
      "Epoch>3, 13/31, d1=0.000, d2=1.162 g=0.427\n",
      "Epoch>3, 14/31, d1=0.000, d2=0.993 g=0.525\n",
      "Epoch>3, 15/31, d1=0.000, d2=0.844 g=0.622\n",
      "Epoch>3, 16/31, d1=0.000, d2=0.743 g=0.709\n",
      "Epoch>3, 17/31, d1=0.000, d2=0.653 g=0.792\n",
      "Epoch>3, 18/31, d1=0.000, d2=0.582 g=0.876\n",
      "Epoch>3, 19/31, d1=0.000, d2=0.522 g=0.965\n",
      "Epoch>3, 20/31, d1=0.386, d2=0.918 g=0.421\n",
      "Epoch>3, 21/31, d1=0.000, d2=1.158 g=0.448\n",
      "Epoch>3, 22/31, d1=0.000, d2=0.978 g=0.542\n",
      "Epoch>3, 23/31, d1=0.000, d2=0.826 g=0.628\n",
      "Epoch>3, 24/31, d1=0.000, d2=0.732 g=0.692\n",
      "Epoch>3, 25/31, d1=0.000, d2=0.675 g=0.740\n",
      "Epoch>3, 26/31, d1=0.000, d2=0.634 g=0.783\n",
      "Epoch>3, 27/31, d1=0.000, d2=0.600 g=0.823\n",
      "Epoch>3, 28/31, d1=0.000, d2=0.561 g=0.872\n",
      "Epoch>3, 29/31, d1=0.000, d2=0.528 g=0.929\n",
      "Epoch>3, 30/31, d1=0.000, d2=0.485 g=1.001\n",
      "Epoch>3, 31/31, d1=0.000, d2=0.446 g=1.095\n",
      "Epoch>4, 1/31, d1=0.000, d2=0.384 g=1.210\n",
      "Epoch>4, 2/31, d1=0.000, d2=0.346 g=1.352\n",
      "Epoch>4, 3/31, d1=0.092, d2=0.869 g=0.371\n",
      "Epoch>4, 4/31, d1=0.000, d2=1.323 g=0.351\n",
      "Epoch>4, 5/31, d1=0.000, d2=1.155 g=0.461\n",
      "Epoch>4, 6/31, d1=0.000, d2=0.938 g=0.552\n",
      "Epoch>4, 7/31, d1=0.000, d2=0.825 g=0.612\n",
      "Epoch>4, 8/31, d1=0.000, d2=0.760 g=0.659\n",
      "Epoch>4, 9/31, d1=0.000, d2=0.709 g=0.705\n",
      "Epoch>4, 10/31, d1=0.000, d2=0.669 g=0.732\n",
      "Epoch>4, 11/31, d1=0.000, d2=0.641 g=0.754\n",
      "Epoch>4, 12/31, d1=0.000, d2=0.628 g=0.774\n",
      "Epoch>4, 13/31, d1=0.000, d2=0.615 g=0.795\n",
      "Epoch>4, 14/31, d1=0.000, d2=0.594 g=0.814\n",
      "Epoch>4, 15/31, d1=0.000, d2=0.581 g=0.831\n",
      "Epoch>4, 16/31, d1=0.000, d2=0.570 g=0.852\n",
      "Epoch>4, 17/31, d1=0.000, d2=0.553 g=0.868\n",
      "Epoch>4, 18/31, d1=0.000, d2=0.543 g=0.883\n",
      "Epoch>4, 19/31, d1=0.000, d2=0.531 g=0.897\n",
      "Epoch>4, 20/31, d1=0.000, d2=0.522 g=0.909\n",
      "Epoch>4, 21/31, d1=0.000, d2=0.512 g=0.927\n",
      "Epoch>4, 22/31, d1=0.000, d2=0.503 g=0.939\n",
      "Epoch>4, 23/31, d1=0.000, d2=0.493 g=0.954\n",
      "Epoch>4, 24/31, d1=0.000, d2=0.483 g=0.970\n",
      "Epoch>4, 25/31, d1=0.000, d2=0.463 g=0.989\n",
      "Epoch>4, 26/31, d1=0.000, d2=0.458 g=1.019\n",
      "Epoch>4, 27/31, d1=0.000, d2=0.444 g=1.040\n",
      "Epoch>4, 28/31, d1=0.000, d2=0.437 g=1.060\n",
      "Epoch>4, 29/31, d1=0.000, d2=0.425 g=1.086\n",
      "Epoch>4, 30/31, d1=0.000, d2=0.402 g=1.113\n",
      "Epoch>4, 31/31, d1=0.000, d2=0.387 g=1.150\n",
      "Epoch>5, 1/31, d1=0.000, d2=0.372 g=1.205\n",
      "Epoch>5, 2/31, d1=0.000, d2=0.352 g=1.259\n",
      "Epoch>5, 3/31, d1=0.000, d2=0.323 g=1.334\n",
      "Epoch>5, 4/31, d1=0.000, d2=0.303 g=1.409\n",
      "Epoch>5, 5/31, d1=0.000, d2=0.275 g=1.518\n",
      "Epoch>5, 6/31, d1=0.000, d2=0.244 g=1.601\n",
      "Epoch>5, 7/31, d1=0.000, d2=0.214 g=1.727\n",
      "Epoch>5, 8/31, d1=0.000, d2=0.185 g=1.893\n",
      "Epoch>5, 9/31, d1=0.000, d2=0.155 g=2.003\n",
      "Epoch>5, 10/31, d1=0.000, d2=0.133 g=2.205\n",
      "Epoch>5, 11/31, d1=0.008, d2=0.135 g=2.132\n",
      "Epoch>5, 12/31, d1=0.000, d2=0.127 g=2.250\n",
      "Epoch>5, 13/31, d1=0.000, d2=0.104 g=2.412\n",
      "Epoch>5, 14/31, d1=0.000, d2=0.087 g=2.582\n",
      "Epoch>5, 15/31, d1=0.000, d2=0.074 g=2.775\n",
      "Epoch>5, 16/31, d1=0.000, d2=0.083 g=2.662\n",
      "Epoch>5, 17/31, d1=0.000, d2=0.286 g=1.878\n",
      "Epoch>5, 18/31, d1=0.000, d2=0.206 g=2.537\n",
      "Epoch>5, 19/31, d1=0.402, d2=0.199 g=2.245\n",
      "Epoch>5, 20/31, d1=0.000, d2=0.097 g=2.994\n",
      "Epoch>5, 21/31, d1=0.000, d2=0.094 g=3.057\n",
      "Epoch>5, 22/31, d1=0.000, d2=0.305 g=2.826\n",
      "Epoch>5, 23/31, d1=0.000, d2=0.051 g=3.951\n",
      "Epoch>5, 24/31, d1=0.000, d2=0.013 g=4.758\n",
      "Epoch>5, 25/31, d1=0.000, d2=0.008 g=5.106\n",
      "Epoch>5, 26/31, d1=0.000, d2=0.005 g=5.349\n",
      "Epoch>5, 27/31, d1=0.000, d2=0.005 g=5.621\n",
      "Epoch>5, 28/31, d1=0.000, d2=0.004 g=5.667\n",
      "Epoch>5, 29/31, d1=0.000, d2=0.004 g=5.650\n",
      "Epoch>5, 30/31, d1=0.000, d2=0.003 g=5.987\n",
      "Epoch>5, 31/31, d1=0.000, d2=0.003 g=6.023\n",
      "Epoch>6, 1/31, d1=0.000, d2=0.002 g=6.069\n",
      "Epoch>6, 2/31, d1=0.000, d2=0.002 g=6.129\n",
      "Epoch>6, 3/31, d1=0.000, d2=0.002 g=6.213\n",
      "Epoch>6, 4/31, d1=0.000, d2=0.002 g=6.249\n",
      "Epoch>6, 5/31, d1=0.000, d2=0.002 g=6.467\n",
      "Epoch>6, 6/31, d1=0.000, d2=0.001 g=6.364\n",
      "Epoch>6, 7/31, d1=0.000, d2=0.002 g=6.547\n",
      "Epoch>6, 8/31, d1=0.000, d2=0.001 g=6.450\n",
      "Epoch>6, 9/31, d1=0.000, d2=0.002 g=6.625\n",
      "Epoch>6, 10/31, d1=0.000, d2=0.001 g=6.486\n",
      "Epoch>6, 11/31, d1=0.000, d2=0.001 g=6.820\n",
      "Epoch>6, 12/31, d1=0.000, d2=0.001 g=6.786\n",
      "Epoch>6, 13/31, d1=0.000, d2=0.001 g=6.897\n",
      "Epoch>6, 14/31, d1=0.000, d2=0.001 g=6.915\n",
      "Epoch>6, 15/31, d1=0.000, d2=0.001 g=6.848\n",
      "Epoch>6, 16/31, d1=0.000, d2=0.001 g=7.075\n",
      "Epoch>6, 17/31, d1=0.000, d2=0.001 g=6.790\n",
      "Epoch>6, 18/31, d1=0.000, d2=0.007 g=5.279\n",
      "Epoch>6, 19/31, d1=0.000, d2=0.006 g=5.465\n",
      "Epoch>6, 20/31, d1=0.000, d2=0.008 g=5.112\n",
      "Epoch>6, 21/31, d1=0.000, d2=0.007 g=5.405\n",
      "Epoch>6, 22/31, d1=0.000, d2=0.006 g=5.582\n",
      "Epoch>6, 23/31, d1=0.000, d2=0.004 g=5.839\n",
      "Epoch>6, 24/31, d1=0.000, d2=0.004 g=5.978\n",
      "Epoch>6, 25/31, d1=0.000, d2=0.004 g=5.659\n",
      "Epoch>6, 26/31, d1=0.000, d2=0.043 g=4.089\n",
      "Epoch>6, 27/31, d1=0.000, d2=0.108 g=3.812\n",
      "Epoch>6, 28/31, d1=0.000, d2=0.142 g=3.830\n",
      "Epoch>6, 29/31, d1=0.000, d2=0.303 g=3.602\n",
      "Epoch>6, 30/31, d1=0.000, d2=0.226 g=2.976\n",
      "Epoch>6, 31/31, d1=0.000, d2=0.200 g=5.025\n",
      "Epoch>7, 1/31, d1=10.847, d2=7.066 g=0.000\n",
      "Epoch>7, 2/31, d1=0.000, d2=8.767 g=0.019\n",
      "Epoch>7, 3/31, d1=0.000, d2=2.483 g=0.445\n",
      "Epoch>7, 4/31, d1=0.000, d2=0.657 g=1.203\n",
      "Epoch>7, 5/31, d1=41.406, d2=6.259 g=0.002\n",
      "Epoch>7, 6/31, d1=0.000, d2=6.658 g=0.045\n",
      "Epoch>7, 7/31, d1=0.000, d2=1.884 g=1.422\n",
      "Epoch>7, 8/31, d1=0.000, d2=0.050 g=4.339\n",
      "Epoch>7, 9/31, d1=0.000, d2=0.007 g=5.242\n",
      "Epoch>7, 10/31, d1=0.000, d2=0.004 g=5.470\n",
      "Epoch>7, 11/31, d1=0.000, d2=0.004 g=5.570\n",
      "Epoch>7, 12/31, d1=0.000, d2=0.004 g=5.674\n",
      "Epoch>7, 13/31, d1=0.000, d2=0.003 g=5.660\n",
      "Epoch>7, 14/31, d1=0.000, d2=0.003 g=5.838\n",
      "Epoch>7, 15/31, d1=0.000, d2=0.003 g=5.914\n",
      "Epoch>7, 16/31, d1=0.000, d2=0.003 g=5.876\n",
      "Epoch>7, 17/31, d1=0.000, d2=0.003 g=6.082\n",
      "Epoch>7, 18/31, d1=0.000, d2=0.002 g=6.095\n",
      "Epoch>7, 19/31, d1=0.000, d2=0.003 g=6.014\n",
      "Epoch>7, 20/31, d1=0.000, d2=0.002 g=6.113\n",
      "Epoch>7, 21/31, d1=0.000, d2=0.002 g=6.148\n",
      "Epoch>7, 22/31, d1=0.000, d2=0.002 g=6.163\n",
      "Epoch>7, 23/31, d1=0.000, d2=0.002 g=6.205\n",
      "Epoch>7, 24/31, d1=0.000, d2=0.002 g=6.287\n",
      "Epoch>7, 25/31, d1=0.000, d2=0.002 g=6.246\n",
      "Epoch>7, 26/31, d1=0.000, d2=0.002 g=6.391\n",
      "Epoch>7, 27/31, d1=0.000, d2=0.002 g=6.316\n",
      "Epoch>7, 28/31, d1=0.032, d2=1.832 g=0.049\n",
      "Epoch>7, 29/31, d1=0.000, d2=3.845 g=0.109\n",
      "Epoch>7, 30/31, d1=0.000, d2=1.780 g=0.380\n",
      "Epoch>7, 31/31, d1=0.000, d2=0.904 g=0.749\n",
      "Epoch>8, 1/31, d1=0.000, d2=0.535 g=1.235\n",
      "Epoch>8, 2/31, d1=0.000, d2=0.266 g=1.851\n",
      "Epoch>8, 3/31, d1=0.000, d2=0.137 g=2.345\n",
      "Epoch>8, 4/31, d1=0.000, d2=0.086 g=2.650\n",
      "Epoch>8, 5/31, d1=0.000, d2=0.067 g=2.865\n",
      "Epoch>8, 6/31, d1=0.000, d2=0.056 g=2.933\n",
      "Epoch>8, 7/31, d1=0.000, d2=0.052 g=3.069\n",
      "Epoch>8, 8/31, d1=0.000, d2=0.045 g=3.154\n",
      "Epoch>8, 9/31, d1=0.000, d2=0.040 g=3.256\n",
      "Epoch>8, 10/31, d1=0.000, d2=0.039 g=3.338\n",
      "Epoch>8, 11/31, d1=0.000, d2=0.038 g=3.430\n",
      "Epoch>8, 12/31, d1=0.000, d2=0.032 g=3.540\n",
      "Epoch>8, 13/31, d1=0.000, d2=0.029 g=3.533\n",
      "Epoch>8, 14/31, d1=0.000, d2=0.028 g=3.664\n",
      "Epoch>8, 15/31, d1=0.000, d2=0.026 g=3.741\n",
      "Epoch>8, 16/31, d1=0.000, d2=0.024 g=3.757\n",
      "Epoch>8, 17/31, d1=0.000, d2=0.023 g=3.797\n",
      "Epoch>8, 18/31, d1=0.000, d2=0.022 g=3.846\n",
      "Epoch>8, 19/31, d1=0.000, d2=0.020 g=3.981\n",
      "Epoch>8, 20/31, d1=0.000, d2=0.020 g=4.068\n",
      "Epoch>8, 21/31, d1=0.000, d2=0.018 g=4.088\n",
      "Epoch>8, 22/31, d1=0.000, d2=0.017 g=4.142\n",
      "Epoch>8, 23/31, d1=0.000, d2=0.016 g=4.173\n",
      "Epoch>8, 24/31, d1=0.000, d2=0.017 g=4.205\n",
      "Epoch>8, 25/31, d1=0.000, d2=0.016 g=4.183\n",
      "Epoch>8, 26/31, d1=0.000, d2=0.014 g=4.388\n",
      "Epoch>8, 27/31, d1=0.000, d2=0.013 g=4.328\n",
      "Epoch>8, 28/31, d1=0.000, d2=0.013 g=4.388\n",
      "Epoch>8, 29/31, d1=0.000, d2=0.013 g=4.417\n",
      "Epoch>8, 30/31, d1=0.000, d2=0.012 g=4.483\n",
      "Epoch>8, 31/31, d1=0.000, d2=0.012 g=4.485\n",
      "Epoch>9, 1/31, d1=0.000, d2=0.012 g=4.528\n",
      "Epoch>9, 2/31, d1=0.000, d2=0.012 g=4.588\n",
      "Epoch>9, 3/31, d1=0.000, d2=0.011 g=4.622\n",
      "Epoch>9, 4/31, d1=0.000, d2=0.011 g=4.659\n",
      "Epoch>9, 5/31, d1=0.000, d2=0.010 g=4.652\n",
      "Epoch>9, 6/31, d1=0.000, d2=0.009 g=4.785\n",
      "Epoch>9, 7/31, d1=0.000, d2=0.009 g=4.797\n",
      "Epoch>9, 8/31, d1=0.000, d2=0.009 g=4.751\n",
      "Epoch>9, 9/31, d1=0.000, d2=0.009 g=4.907\n",
      "Epoch>9, 10/31, d1=0.000, d2=0.008 g=4.858\n",
      "Epoch>9, 11/31, d1=0.000, d2=0.007 g=4.899\n",
      "Epoch>9, 12/31, d1=0.000, d2=0.008 g=4.907\n",
      "Epoch>9, 13/31, d1=0.000, d2=0.007 g=4.935\n",
      "Epoch>9, 14/31, d1=0.000, d2=0.006 g=5.028\n",
      "Epoch>9, 15/31, d1=0.000, d2=0.007 g=5.057\n",
      "Epoch>9, 16/31, d1=0.000, d2=0.007 g=5.034\n",
      "Epoch>9, 17/31, d1=0.000, d2=0.007 g=5.055\n",
      "Epoch>9, 18/31, d1=0.000, d2=0.007 g=5.056\n",
      "Epoch>9, 19/31, d1=0.000, d2=0.006 g=5.136\n",
      "Epoch>9, 20/31, d1=0.000, d2=0.006 g=5.136\n",
      "Epoch>9, 21/31, d1=0.000, d2=0.005 g=5.175\n",
      "Epoch>9, 22/31, d1=0.000, d2=0.006 g=5.157\n",
      "Epoch>9, 23/31, d1=0.000, d2=0.006 g=5.268\n",
      "Epoch>9, 24/31, d1=0.000, d2=0.006 g=5.219\n",
      "Epoch>9, 25/31, d1=0.000, d2=0.005 g=5.274\n",
      "Epoch>9, 26/31, d1=0.000, d2=0.006 g=5.387\n",
      "Epoch>9, 27/31, d1=0.000, d2=0.005 g=5.303\n",
      "Epoch>9, 28/31, d1=0.000, d2=0.005 g=5.262\n",
      "Epoch>9, 29/31, d1=0.000, d2=0.005 g=5.265\n",
      "Epoch>9, 30/31, d1=0.000, d2=0.005 g=5.367\n",
      "Epoch>9, 31/31, d1=0.000, d2=0.005 g=5.379\n",
      "Epoch>10, 1/31, d1=0.000, d2=0.005 g=5.459\n",
      "Epoch>10, 2/31, d1=0.000, d2=0.005 g=5.496\n",
      "Epoch>10, 3/31, d1=0.000, d2=0.004 g=5.464\n",
      "Epoch>10, 4/31, d1=0.000, d2=0.005 g=5.465\n",
      "Epoch>10, 5/31, d1=0.000, d2=0.004 g=5.464\n",
      "Epoch>10, 6/31, d1=0.000, d2=0.004 g=5.574\n",
      "Epoch>10, 7/31, d1=0.000, d2=0.004 g=5.539\n",
      "Epoch>10, 8/31, d1=0.000, d2=0.004 g=5.589\n",
      "Epoch>10, 9/31, d1=0.000, d2=0.004 g=5.643\n",
      "Epoch>10, 10/31, d1=0.000, d2=0.004 g=5.574\n",
      "Epoch>10, 11/31, d1=0.000, d2=0.004 g=5.626\n",
      "Epoch>10, 12/31, d1=0.000, d2=0.003 g=5.641\n",
      "Epoch>10, 13/31, d1=0.000, d2=0.003 g=5.679\n",
      "Epoch>10, 14/31, d1=0.000, d2=0.003 g=5.653\n",
      "Epoch>10, 15/31, d1=0.000, d2=0.004 g=5.690\n",
      "Epoch>10, 16/31, d1=0.000, d2=0.003 g=5.821\n",
      "Epoch>10, 17/31, d1=0.000, d2=0.003 g=5.848\n",
      "Epoch>10, 18/31, d1=0.000, d2=0.003 g=5.807\n",
      "Epoch>10, 19/31, d1=0.000, d2=0.003 g=5.840\n",
      "Epoch>10, 20/31, d1=0.000, d2=0.003 g=5.830\n",
      "Epoch>10, 21/31, d1=0.000, d2=0.003 g=5.916\n",
      "Epoch>10, 22/31, d1=0.000, d2=0.003 g=5.827\n",
      "Epoch>10, 23/31, d1=0.000, d2=0.003 g=5.861\n",
      "Epoch>10, 24/31, d1=0.000, d2=0.003 g=6.002\n",
      "Epoch>10, 25/31, d1=0.000, d2=0.003 g=5.892\n",
      "Epoch>10, 26/31, d1=0.000, d2=0.003 g=5.869\n",
      "Epoch>10, 27/31, d1=0.000, d2=0.003 g=5.918\n",
      "Epoch>10, 28/31, d1=0.000, d2=0.003 g=6.020\n",
      "Epoch>10, 29/31, d1=0.000, d2=0.003 g=5.903\n",
      "Epoch>10, 30/31, d1=0.000, d2=0.003 g=6.003\n",
      "Epoch>10, 31/31, d1=0.000, d2=0.003 g=6.003\n",
      ">Accuracy real: 100%, fake: 100%\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "TRAIN COMPLETE\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe4AAAGFCAYAAAA7JBDPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAlh0lEQVR4nO3df5SkVX3n8c99nqqumoZmhhEQZhxmRBAUUPFXzA/UYDhrTNbj5gdu4o+T3cRNjkk2RxPd3SR6jsZoJB4wCdnEIKiJJ1mTrLsbdzVRgyFEARVERUEBYZxhRn7MDEP31I9+6t67f8xUp2foam41XfPcW/f9OofznGb6x7ee+9z7ee5zn3rKeO+9AABAEoq6CwAAAOEIbgAAEkJwAwCQEIIbAICEENwAACSE4AYAICEENwAACSG4AQBISCP0G7d/8HL9xPNu0c9uvkmzZqDTy8P/f7ZoqvJWLXN42zSl+r56zNdNU6rnB2qqVMdXaptSHW/VMoU6zmq2KI/azhUN9bzVrGmq7wdqmYYqWbVNQz0/UNs0Vvy7y//O8OeW/73ZZdvlv79pCvW8VdMUmndWpaRvVSfps/Pn6/998GJ99Q/fNKEmeOK2f/By/dhFX9PPPOlGnWAqbWkMZL1f2oftI6+1eWRft02hee80a4zmndcJhdEh5zVXGHW815wp1PNOs0WpvneP2Vct05CTU9OUR7VBacxSW1jvl/59te2wzYZfD9tueVsPj5mmKXTQWUnSNxefpE8+8iz9yzXP121//OaaW2BlZ/3Vu/VzF96oyzbeorbxOqWYkZNTyzTl5NRQqYHs0rZQISenQsVR+2n5fl2+XX7sD7fLf+/y3/N4+/nxfu9qv780Rh1XycrrO4MZfXr+Qv3NNZfo61fG22fO+d0r9IKX3aFfOf0fNVcs6ikNyXmvE4vWiq911HalthqOT6O2x+7rY8fLkH2/fOvkVchIkkpTyHq3tJWkgQ73mf22ry/1T9N//fOf053viLNttl99uX7qBV/W6zbfqLaxenJZyHmv2aI5ckw5dr8M98dq+2X5dr0d+/srb4+qZ3jc9H0lSdo1cLqhe7b+6EOv0jd+L6xdTOiT0z5+z0V6SftBnVS0J/JiY2S90z7X1Tu/d4n++/M+Wnc5I/3N3c/TJRu+pxOLlpqmrLuc46LyVg/Yrt6250f1kRdeW3c5K/rMvefp+1qHtMHMZNVnDriu3vPgxbryoo/VXc5If3HXi/SK2V1ZjWeS1PeVPvroNr3h3BvqLmVFn/jOhfqh9gGdaFpZtcuC6+mPD1yo/3b+J4O+Pzi4992/VSeXs0+ouBRZ7/Ttqqfzz7y/7lJGyrVtKm/1tUWrF2zfWXcpK3p0zzadWLTrLuO4s97pvkFH52zbW3cpI+XaZ6TDIXHSll11l7GiA3ueoo3FhrrLqMWD9pBO37on6HuDT2lmi+aaC0pZaQqdWsb9OPcTi1bdJdSiaUptKRfrLmOkDWam7hJqUZpCm4u4Z0u59hlJapl4x/LZTPuMJJ04RrsE966G8rgEu5J25Jefh+s4OZot4m2bnC71HSv2E/2c+0zMy2k5t0vLBN9yxl3lIYrId1POAdHM+IQSa5dzn4kZ7RImeC/lvENjPkPNHW0Tp5yv0AFrMU7G5pvGAAAkiOAGACAhBDcAAAkhuAPkfKcjACAuBDcAAAkhuAEASAjBHcAp7ien5czJ1V0CABxXBHcA1rgBALEguAEASAjBDQBAQgjuAKxxx8uGfSotgCOs576Q1BHcAVjjjldpaBtgHDl/7sS0oAWRNGbcwHiYcaeP4AYAICEEdwDWuAEAsSC4AQBICMENAIgC6+9hCG4kjUeeAuNh6S99BPcUyPks1TIIAcgMwY2klbzHHpgaXA0IQ3ADAJAQghtJ41I5MD24ZyUMwT0FuLwEYBrwJMQwBPcU4CwVseF52PGK+bMXGMvC0LumAGepAELFfIWOpa8wBDeSxl3lwHiinnEzCQlCcE+BnC8vcYYep5yfLRA7ZtzpI7gDxHyGmrumyrpLwApY444X41n66F0A1h0zbqwFR00YgnsKFDQjgCnASBaG/RQg5jUhKe81bgDTo+LmtCAEd4DY14RynnGXJu62AYD1Fjzis2YFAED98p2qTZGcZ505X20A1iLmO/5zHsvGEW8LIljOT05jfR8YT8xXT3Mey8ZBcAeI+QxVyvsslRk3MJ7YxzM8PloQABCFnCch4yC4p0DOs87Y7/gHEC7fkWw87KcAMa8JAQDyQnAHYE0IACaPT/sLQyIBAKJQsMYdJDi4mXXGi3VeANOAGXcYnpw2BWJ/ljoAYP0w4waw7hgvsBY5v0NmHOwlAEAUeB93GIIbABAFZtxh2EtTIOfndbO+DyA3BPcU4CwVAPLBiD8Fcp5xA0BuCG4kjZMWALkhuKdAzp9hm/NrB9Yi5mdycCIehuAOEPOBLuV9sOf82gHkiSenTYEq47aJ+bXn3Gdif+2x1zdJA9m6Sxgp5yto4xyTwcGd89tuYj7QJamSz3Ygms/0dQNr1fODuksYqYp8rJ2kcTI2OLj7vlpTMdNg3i3WXcKq9gwaWZ5YWe/0Pduqu4yRuj7u42aS+hGHgyQt+H7dJdRmv403HPdbm+0kZMGFH5PBwb0n0x1qvdPdVbvuMlZ1Q+fpOuB6qny8HXISFnxfn1t4Zt1ljLRr4LLsM5K018Z90nJ3VWbXX6TDE7AbujvqLmOkL/W3qusXs+s31jvdNWgGf39wcL//wZdpr+2oE/nscz1Z7/TdQUfXPPTiuktZ1ZW3vEx/f2i77qgqHbAdHXRd9X2lvq9kvVPlD590DTtDqp1i+Br6vtKC6+n67pP0oTteVHdZI13xwKXZ9RlJOmA7+uTC+XWXsarfuPunde+gpwXXO6pvTKvhOPDVRel9d15adzkjvf22V+oLvTndbztHjWHT3D7WO91vO/rAAz8c/DPG+4zvBgAAIDG8HQwAgIQQ3AAAJITgBgAgIQQ3AAAJIbgBAEgIwQ0AQEIIbgAAEkJwAwCQEIIbAICEENwAACSE4AYAICEENwAACWmEfuP2D/y+LnvRF/X6k2/UrLE6tTz8oy3TlJNTQ6WcvAqZVbdNc/jj9JqmlPVOpSlGbh/PqJ+rvA2qY6Wfl6TBkQ9zf8D2dVNvq97x4dfojne9aS3797g4+71X6OwX7dTrt9youbKrHY0DsjLaXAzU8UabCqnnveZMoUPeaa4oVXmnWdNUJau2aajyVi3TPLJtBLXlStuBrAoVcnIqVCy1dd9XappSPT9QU6U6vlLblJp3A7VNoZ53ai+rr++dZk2pjrdqmUIdZ9U2hfa7w2309cXT9akDF+rLH3yOvvKnb665BVZ2wVuulC4+oH9/1q3a3FjQhe1dsip0enlIPV9qUzHQvCs1V1g94hqaMwN1/OGv512pjYVV30tzhdEh57WpKFTJa9Ycbr+WaazYfk1TLu3/5duGSg1kR25D2q3vB2qZhjq+UtMUmndWM8ZonzWSpFv72/SpfRfqzmueoVuvjrNdJOn8t16pmZc8rNed9UVtLhd0fmuPrIxOL/vqHdNnet5prmg8Zp9b75f29ajxL2ScGzUOHdunjm2T4df/Op76x7RZKaN5N1BpjO6sTtCnH71Q//eai/W1P4hzPDv/v1yp0/7Nbv3q9uu0qejo7OajcpI2Lhuzlh+Dx37dNqV63i5tl//7sdtRfWelbWnMiv9/pZ87tq+NGiOHHyu71y7q890deu9HLtMdvxvWLsGfDvb333mmfqA9rw1mJihUp0XHLepDjz5Nv3redXWXMtJ7v/lyvfqkr+qUYkYtc/iEaprbyHonJ6+9tqvf3P3j+ssXXV13SSt67c0/r185/R91TqPSbNFUoUKFDgdcyACeGuudBrLaPejr1+/7Sf3dxVfVXdJIv37bZfqPmz+vbY1CLdNUIZPkPh+H9U4HXFfvfOCluuq5f1l3OSt6zzdeodds/IpOLVtqqJz6NhnquEX92cGn683P+EzQ9wcH96N7tunEov2EikvVQdfVyVt2113GSPfsOkNnNmazOciHKm/1lUWnF22/r+5SVnTdvefqha2eZouZuks5rvq+0r/02rr0qXfWXcpI3/juVp3dbKlpyrpLOa6sd7pn0NV52/bUXcqK7tt9hraW+Y1lkvSwPaTTtoa1S/De2WDyGnyWa5vgFYVanFo2sjzQm6bUtrJfdxkjbWnML10ByUnLNLWjcbDuMlZ1eqnsQls6fKXn1MLUXcZIpxR5XdFdbm6ME/zgPZTrzpSkhuLu4C3TrLuE2swV8Qbjpny7jOYiDgdJmi3y7TMxv/YcT6aGxsmZjIeW6TFcN81REfEhXCjfE95m5MdkzMdNznIey8bB0Rsg18E3BTGfoZcZD0KxLxHkHBAxX0HMeawd57Xnu5cwFWIegAsTb225yzkgkD6O3inAIBSnnGfcJSctwMQw4gMTYhX0TksAWHrwTgiCG0njakOcuPkrXvSZOLHGjWyMc5aK48eJdgHGwYwb2WD2ACA3jHpIWswzbhf2NGEAkBvjnhiCG0ljxh0n1riB8Yzz1lZ6F5IW84ybu8oBhGLGDQDAlCK4gQmJ91rA5HFXOTCecfoMwQ1MiPU+6kv5AOIxzn0hBDcwQdw8B2C9MaoAE8SMG8B6I7inQM7hMM6dmHXIdcZteQ87MBbWuIFI5HpSxaeDAeNhjRuIQGlMtjNuAJPDqIKk8bYjALkhuAPEfrkz9nXeSYp5LTXm2iYt59cOTBrBDUxIzuu8Ob92YC14VnlmuFwMAPkguAPkfCk6dpy0xIlL5cDkENwBYg+HnAfJmD+BK+d2ATA5BPcUiP3EIlc5r/Pm/NqBSSO4A8Q+c4p51ok8xd5ngJQR3EiaizggmmPcJQoAoQjuAJVs3SWsqor8feaTxNWGOLF8A0wOwR2gqbLuElaV8xBZRjyrLTJe5x3nucsAxkPvmgKsJ8Yp5pMKAOkiuKdE7I9lzVHTxH2lBkCaCO4pUNVdAHAM1riBySG4A/CeVGA8rHED4xnnI4DpXVOgYok7SoQXgFDjLHcysgSIfQCOuzoAwHpizA8Q+3pd3NUhR7H3GSBlBHcAZtzxyvm90jGLvc8AKaN3TYEy4+zivdIAckNwT4Fm3QVgRQUnFQAmgOAOkMJ63ThvJQAApIvRPkDs63U5v8+cp5PFKedjEpi0uBMJAAAcheCeAnzuMwDkg+AGACAhBPcUyPm9zLHff5Ar2gWYHHrXFOC9zACQD4I7QOzvx+XOagDIB8EdwCnuj9/isiQA5IMRP0DsM+6c0TZxol2AySG4p0DOg2TsV0MAYL0R3AEIBwBALAhuJC3m58jnfMKX82sH1mKcPkNwB4g5HAAAeQkObuvzDS/r45495Dy7qbytu4SRYq4td3mPZ/m+9piNM14EB3fW4aC4B+Ccrwj0Ig7HnNuFk5Z45TyWx6zvB8HfGxzcC66/pmKmwX4b9yDUcVXdJdTmIRvvHfX73SDb2c2Cj/uY7PrFukuoTT/itsm1v0jSfhf+2oOD+65BM8uz6L6v9KX+1rrLWNXOQfmE28Z6d9R/Kei4RX2pd2bdZYz09cVT1PWLyezP9VJ5qzurE+ouY1U7Bz7L8cx6p12DeI/HR12v7hJq0feVbuptD/7+4OB+610/rburvhZcL8qBaFjTsdsn8vsqb3XHotMffudlT7i+Sbp8z8t176CnA7ajytulAWmlfWK9U99XqrzVQdfVgutp72BBB1xXe21HB1xXD9qODrquHraH1HGLOui66vtKfV8t7Zflv/d4G76Gry2W+rP7XlxLDSHeddeP6dbFtvbazlH7b9SxOqq9hv9V3gZtQ3/v8p+rvFXHLarvKy243tJ2+G+hJ3TWO3130NVfPPSD67UbJ+I9e35UuwdddVxeM+99rqv/+ehz6y5jpI/NnxNtxkzCsP/dvuj1B3dfEvxzxvvI77wCAABLeDsYAAAJIbgBAEgIwQ0AQEIIbgAAEkJwAwCQEIIbAICEENwAACSE4AYAICEENwAACSG4AQBICMENAEBCGqHf+PS/faf+wzNu0ivnvqq2cTq1bMjKq20ast6raQ5/QlVpjHp+oKZK9f1ATVOo563aplTHW7VMoY6zmi1KdZxV2xQ65J3axqjjvdrGaN55zRVGh45sO95rzhTqeae5oqGet5o1TTm5pb/bMs2lv195u/T/m6Y8qp6WaajjK7VNqcq7o76edwM1jdH+I8+3v7X3FP3DgQv09Wsu0K0fePOk2uAJO/tj79Ibn3W9fmLudrWN0clFW05OLdOU9U6lKR6zPdax/155q0JGTl6FjAayaqhc2g7//1q3klasa9R2WM/wM2sfsIv6Qm+73v3hV+uO333Tcd3foc76q3frjc++Xj910tfUNkYbixlJetz91zRl8H5Zbyv9HUmP256DI59Z/5Dt6+beFr3tI6/Vnb8TZ7tI0vlvvVInX7pXb9zxT5oruzqnuU/WGz2p9EeNO7NHxqMTAsej4TjUMo2j+so4bTrq2Je04tfj9Jkbujt0+Ycv0zffHWfbPPcXr1D/FQf180//gk5vHNSFrT2SpCeXTj3vNVccHrdnTXNpPK9k1TYN9fxAbdM4avwftse/ft14zBgmaV36VGjfGciqULH08aq7Bk43dM/WH137Kn3jvWHtEvwhI9fde66e3+pog5mZyIARG+udnLx2D7p6y3dfpY//4J/UXdJIN+3coWfPSC3TrLuU46rjFvWnj5yn33jmP9RdyopybpePzu/QL517fd2ljPSu239cr910i55cttRQKUlZjGux95k3fPn1+s+nXaftDaOWaaqQyaJdFlxP79//HL39gk8EfX9wcD+6Z5tOLNpPqLgU9X2lm/tNvXTHXXWXMlJ3747swmHoYXtIp23dU3cZK8q5XQ66rk7esrvuMka6b/cZ2lrOZhEKx4q5z9y680ydP9NQ05R1l3Lc7R0saOtT9gZ9b/BRm+sA1DJNbSsX6i5jVcMZQ47mjlx+jlHO7TJr4m0XSdpcNLIMbSnuPrOlMcgytCVprgheuQ4P7lx3piRtKuLu4LkOQFLc4ZhzuwzXDmOV60REirvPzGacM+Mck/mOLGMoTNyDEBCb2E9aYj+xyFXOE8RxxN27ItE24ZcwcHzFHhCIU87HTcyvvcg4ksY5mcx3LwEAkCCCO0DOZ4EAcLywhBGGRAIAICEENwAACSG4AQBICMENAIhCzHe8x4S9FMDJ1V0CRhg+yB8AUuYU9PRxSQR3EO4qjxdn6ACmAe/jBgBgShHcSBqXygHkhuAOwBo3gGnByW6cWONeZ6xxA5gW3BcSJ9a4AQArYsadPoI7AM/Pjdc4l5cAYBoQ3AEIh3hx/wGAacAa9zpjxg1gWrDGHSfWuAEAK2KNO07MuJEN61nGAMbBjDtOzLgzk/MZNGvcwHhyHi9ixox7nXGGCmBaMJ7FiRk3EAFmNgAmgeAGACAhBDeSZiN+jz3v/48XV0OQMoIbSSt5jz2AKTDOvQcENzAh3PEeL66GIGUENwAACSG4kbSY17gRr5yvhrC+H6dx2oXgRtJY4wbGw/u448QaNwAAU4rgRtIKDmEAmWHUA5AdPpwGKSO4kbTSsMaN8eV8cxrSR3ADE8JlfACTwMiCpBGOAHLDqBeA9z3Gi0ueWAve/4+UEdwBeN9jvBoq6y4BCeL9/0gZiRSAGTfWoiAcAEwAwT0FuCIAjId7I5Ayjl4AABJCcCNpMV9tiLm23PH+f6SMkQVJ4/4DrAWXypEyjl4kjVkt1oIbB5EyRj0kjRk3gNwQ3AGY1cWLtgGQG0Y9AAASQnADyA5XapAyjl4kjTVuALkhuJE0Zk4AcsOoB0wIVwMATALBjaQRjgByQ3BPAcILseGYBCaH4EbSnHzdJYwUc20A0hUc3JxBxyvngHCK97iMubZJy/mYjF3MY3nMtU3aOK+dGXeA2A+mytu6S6hNzw/qLmGknNsl9tcee5+epJhPqmKubdLGee3Bwd2PeICctIHiHoQOusW6S6jNfhtv2zxkB9kGxIKv6i5hVbH36Unq+HjHi5hrm7T+GH0mOLh32yrbQegB26+7hFXduniKOhmGd99Xurm3re4yRrq5t01dv5hdv6m81W39TXWXsao9g3527SIdvtJwbxXvhda7qzL6qzWTYL3TzsEEZtxXPfRS7bUddVxeA9FB19VnDp1ddxmreutXf1JfWWzoQXtIlbdZHPiVt7pj0en997ys7lJG+q0vvkpf6M1pr+2o76uldplU/xn+3nG3613DvYOe3r/r0nX/3evpyod+WPtcd6xZTuqsd3rQdvTBh19cdykjve2+V+neQU8LrifrXTZZc8B19dcHnx/8/cZ7n++iAgAAiYn3mgkAAHgMghsAgIQQ3AAAJITgBgAgIQQ3AAAJIbgBAEgIwQ0AQEIIbgAAEkJwAwCQEIIbAICEENwAACSE4AYAICGN0G/c8Rfv0S9c9Hm9euMtahrplGJGTk4t05STU0OlnLwKGQ1k1VC56rZQISenQoUqb9U05djb4c8fux3n51eqq+8rFSq01y7q890duvzDl+mb737TJNvhCXnuG65Q78ce1S+c+3ltLhf0rNb9sjJ6crmovpc2FkYd7zVrjOad19yRr+dMoUPeaa4o1fdOs6ZUx1vNmlKVd2qZhipZtU3jMfvOej9yXy5vg76v1DSlen6gpkp1fKWmKdRxVu0jf/8EU6jnneaKhnreavbIMbX82Fr+eyXpYbeoL/W26Lf+x2v07d9+c80tsLJLP/cm/fKZ1+klG/aplNEGMyMnf2T/OZWmGLmtvFUhs9SnHm87qo8d2w7Dr3t+oLZpLG0rb1fsy5KOqutYy+uVpIdtVzf3T9dvfuT1uvOd8faZHR99j37xoht02UlfUdtIm8uWrPdqmcbSPny8fft4483yY3/5vh5uh31o+T5f7dgYV4ptc/blV+iHL7lNv3za53SCGeiM8nDODPvO8Jg/eix67P6SFNxnQvtYaL4dW+dqfVySDrqebu1v0q999A361tvD2iX408FuuO9pumhmoJZprOkgSlXHLeqag+fo157x2bpLGemXbnmdfvXU67StUahlmipksmijjlvUR+d36JfOvb7uUlZ03+4ztLWczaItluv7Sh95dHu07SJJN+3coWfPSC3TrLuU4yr2tvn4PRfpRzY8rA1mJqt+0/eV/tfCafrZc74Y9P3Bwb2wZ7tmi5knVFyqDtiOnrT1/rrLGOm2727TM5pNNU1ZdynHXcxtU+19WlaDz3ILrqeTtuyqu4yRunt3ZBfaQzG3zYE9T9HGYkPdZdSi4xZ14padQd8bPKq0TPBV9akzW8TdwbeUNsvQluJum1xDW4p/Jht7fZMU82ufNXlODqXxMjZ4ZMl5EGoo7lCcjbgjTlrsbZOrXE8kUxBz28Rc26SNk7H5pvEUKY2puwQAwHFCcAeI/WpDkXEzxt42ALDeGPWmwPBtOwCA6UdwAwCQEIIbAICEENwAACSE4J4C3KAFAPlgxEfShs8lBoBcENwAACSE4AYAICEENwAACSG4kTSnoA+3A4CpQXAjaU7cnAYgLwQ3kpbzc9oB5IlRD0ljxg0gNwQ3kmY9a9wA8kJwI2nMuIHx8NCi9BHcAJARHpGcPloQSbO8HQxrkPOsM+fXPi0IbiTNscYNjIUZd/powQCcocaLGTfWIucH9zCepY/gDsAZKoBpwXiWPlowAGeowHTh3QhIGcGNpDH8AsgNwY2k8QAWrEXOxw1XENNHcCNppTF1lwAkhTXu9NGCwIQwswEwCQQ3AAAJIbgD5Pyez9jlvFYJrAVXgtJHcAcoxDpqrNqs12ENcr43gjXu9NGCSFqR8QAMIE8EN5JWcjUEa1Aw9CFhHL0BWOPGWuR83LCOCkwOwR2ANe54NU1ZdwlIEH0aKSO4AQBICMGNpLFWCSA3jHoAACSE4EbSYl6rjLm2SeO9wsDk0LsArLvY7yrnxAIp4+gNQCePV8xtE3Ntk5bzawcmjd4VIPbZQ85omzjRLsDkENwBmD3Ei7aJE+0CTA69CwCAhBDcAAAkhOAGACAhBDcAAAkhuAEASAjBDQBAQghuAAASQnADAJAQghsAgIQQ3AAAJITgBgAgIQQ3AAAJIbgD8ElHwHhi7zOx1zdJOb/2aUFwB3DydZeAERiE4kSfiRdtkz6CO8CC69ddwqoqb+suoTYxD0I5t0vfV3WXsKquX6y7hNrE3DY595lxXntwcOe6Q613umvQrLuMVR1wvbpLqM3Dtlt3CSPFXNskWe/0nUHdVazuO4M8x7TY2ybXPiNJD4zx2oOD+5Z+fpclrXe633Z09YMvrbuUVX3okefooOtm1z4LrqfPdHbUXcZIf7z/+3XAdrILiH2uq4/s+4G6y1jVb+98lXYPuuq4xVr7zfBvL98O/1v+/9fLg7aja/f90Lr+zvV0xcMXZ9lnFlxPfzt/QfD3G+99vNcaAQDAUVjjBgAgIQQ3AAAJIbgBAEgIwQ0AQEIIbgAAEkJwAwCQEIIbAICEENwAACSE4AYAICEENwAACSG4AQBISCP0G8/+2Lv08xd8Qf/upNvUNl6bi4asvGbNjCpv1TTl0rbvq6O+Xr5tmebS105ODZUayK64dfIqZFbcNk0p651KU6xpK+kxv3cgq0KFOkc+8m/nwOi6Q+fp2mteodvf96bJtMA6OOc9V+j8i+/Wf9ryz5orutre6MhJ2liUqrxT25Tqeau2KdXxVi1TqOOsZotSHWfVNoV63mm2KNX3TrPm8M+1TEOV7FIbt0xjaV9JWtO+7vuBSmPU8wOVMivWM1c0jvr7bdNQzw/UVKkFX6mQtHPQ1PWHztOHP/Ry3f77cbbNjqvepx96wR167ak36qSip+2NrqykTce8vqZK9f1ALdNY2nZ89YTbbfl+6/uBmqZQz1s1j/yepjGad15tIz3iCs0VTvNHth1vtKmQet5rbtnfqbzTrGkeVWfTFNpvD38oxFcXT9enDlyoL1/zHH3lT95cbwOs4sWffYveuONzumTDHpUyOrFoSdJjxhVp9Djh5B6zHTV+rTReDY3bh0aNl8u3hQpV3qo0Rh1XqTBG91aF/qlzrq699hXR9pmzf+8KPfX7duk1W2/SSWVP5zQfkpXR5mKgvpc2FkY973WCKXTIO52w7Nhc3jeWb0f1jWEOWe9XzKthjg3/ffj1sE8Nj/15ZzVjjB5xUtt4zbtSs8bqoGtqY1Gp40ttLKwOulJzhV369/1uRk3jdGvvTH163/n69rXn6darw/pM8IeM3HDf03TRzOHOuvygm3YHXVe///AL9e5nfbzuUkb6ozsv0U+ceIc2ly01VGbTPgddV+/f9zy948L/U3cpK7r6Wxfr3554jzYWM1m0i/VOTl57bVdv3fVK/fX3f6Dukka6c9cWPbXRVtOUdZdyXB10XV2x7/n6nQv/d92lrOhdt/+4fmbjLXpyOaOmKVXIJNlvRp2kLf/3oYGsdg/6+vX7flJ/d/FVQb8/OLgX9mzXbDETWPb0GH60546n7K27lJG+u/sMnVHOJnmAPxHWO+21HZ0Zadvcv/sMnZZhu1Te6ot9o4t33FN3KSP1956VXWgP7R4sRNtn7tp1hnY08uszfV/p+u6sXn7WN4O+P3jvtEzwVfWpUppCG4u4O/imIq+rIEOlKbSpiPe43FjMZNkuTVNqW6NTdxmryjW0JUXdZ04pp//K1EoaKrWj+Ujw9wfvoRx35tCsiftKQ8s06y6hNjG/9lxPdiVpLuPxInYx95l2pn3m8CQk/PvpXUja8EY5xKVJcEcr5j5TZBxJ47zyfPfSGGI+0KX465ukmK8ExVzbpOV8KTp2MR+XOY9l7TH6TLwtCABAJsa52kBwB4j5DFWKvz7kJ+dLnlg7xrIw7KUAy99zF6PY6wMArB+COwBngcB4cl6rBNaiNOF9hkQCAKBmNuxZaJIIbgAAkkJwI2ms7wPIDcGNpHH/QZxoF2A8rHEDADClCG4kjUvlAHJDcAMAkBCCGwCAmvHIUwAAphTBDQBAQghuJM0p/GlDADANCO4pkPN7ZnkmNoDc5DviYyow4waQG4IbAICajXP1kOAOEPtDPmKvDwCwunGuHhLcAXJeQwYATB4z7nXGjBYAEAuCGwCAhBDcAAAkhOAGACAhBDcAAAkhuAEASAjBHSD2p3PFXh8AhOAdPGEI7gA8DztetA2A3BDcAWKf0TpxlgoAuSC4AzCrAwDEguAOEPuM2/q46wMArI5nla8zZtwAgEniWeUAAEwpghsAgIQQ3ADWHe/HBSaH4Aaw7vgMe6wFx00Y9tIUKA03zwFALghuAABqNs7VBoIbwLpjjRsYzzh9huAOEPu6S0EzIjKx9xkgNsy4AdSKGTcwOQQ3AAAJIbgBAEgIwT0FeJY6YsMaNzA59C4AABJCcAMAkBCCGwCAhBDcU4D1RADIByM+AAAJIbgBAEgIwT0Fcn5KlZOvuwQAOK4IbgAAEkJwT4GcZ52Vt3WXAADHFcEdIPZL0U5x1zdJlQjuGMXeZ3IWc9vEXNukTeRjPXPeoX0/qLuEVXVcVXcJtdlv4w3unPtM7FeBcm6bQcQnuzHXNmnj9Jng4H7U9dZUzDTYaxfrLmFVdw2aWV4y7vtKX+pvrbuMkWI/4ZukA5GPFzmPZw/Zft0ljPSQ7Wd7UvWw7QZ/b3Bwf2z+HC24XnY79YDt6BMLF9RdxqreufOVurvq66Drynp33Nto+PeGf7vyVtY79X2lytulbcctLm37vtKC66nvq6X/3/fV0s8v/70r/b2+r3T7otdV915y3F7nuP65N6e+z+9qSMct6qbeqXWXsaq/WThbHbeY3Xi24Hr6bOesussY6c8feZ4OuG52E5EF19MXeluCv9947+O+pgUAAJZwcxoAAAkhuAEASAjBDQBAQghuAAASQnADAJAQghsAgIQQ3AAAJITgBgAgIQQ3AAAJ+f+bCD1x37kVBwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from numpy.random import randn, randint\n",
    "from numpy import asarray\n",
    "\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "\n",
    "import imageio\n",
    "\n",
    "\n",
    "import os\n",
    "os.add_dll_directory(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.7/bin\")\n",
    "\n",
    "#################################################################################\n",
    "n = 1000\n",
    "x_size, y_size = 128,128\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "output_path = 'C:/Users/grant/OneDrive/Desktop/git_projects/python_envs/ATMAN_GAN/GAN/GAN_outputs/'\n",
    "########################## DATA LOAD ############################################\n",
    "# Batched Data Loader required? \n",
    "\n",
    "#Preparing data pathway\n",
    "input_dir = 'C:/Users/grant/OneDrive/Desktop/git_projects/python_envs/ATMAN_GAN/GAN/datasets/landscape/'\n",
    "\n",
    "input_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir,fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "        if fname.endswith('.jpg')\n",
    "    ]\n",
    ")\n",
    "\n",
    "#selecting n random images for training\n",
    "input_img_paths = random.sample(input_img_paths, n)\n",
    "\n",
    "\n",
    "\n",
    "########################## IMAGE PRE-PROCESSOR ############################################\n",
    "\n",
    "dataset = []\n",
    "save_path = 'C:/Users/grant/OneDrive/Desktop/git_projects/python_envs/ATMAN_GAN/GAN/datasets/landscape_clean/'\n",
    "for j, path in enumerate(input_img_paths):\n",
    "\timg = cv2.imread(path)\n",
    "\tRGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\timg_r = cv2.resize(RGB_img,dsize=(x_size,y_size),interpolation=cv2.INTER_CUBIC)\n",
    "\tdataset.append(img_r)\n",
    "dataset = np.asarray(dataset)\n",
    "print(dataset.shape)\n",
    "########################### DESCRIMINATOR #################################################\n",
    "# Input should be 128x128x3 images and the output would be a binary (using sigmoid)\n",
    "# Binary classification (True/False)\n",
    "\n",
    "def define_discriminator(in_shape=(128,128,3)):\n",
    "\tmodel = Sequential()\n",
    "\t# normal\n",
    "\tmodel.add(Conv2D(128, (3,3), padding='same', input_shape=in_shape))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# downsample to 64x64\n",
    "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# downsample to 32x32\n",
    "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# downsample to 16x16\n",
    "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# downsample to 8x8\n",
    "\tmodel.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# classifier\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dropout(0.4))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "#Verify the model summary\n",
    "test_discr = define_discriminator()\n",
    "print(test_discr.summary())\n",
    "plot_model(test_discr,to_file=os.path.join(output_path,'discrim_model.png'), show_shapes=True)\n",
    "\n",
    "\n",
    "########################### GENERATOR #####################################################\n",
    "# Generator generates 128x128x3 images that can be fed into the discriminator.\n",
    "# Start with enough nodes in the dense layer that can be gradually upscaled to 128x128x3.\n",
    "#Input would be a latent vector (usually size 100)\n",
    "\n",
    "\n",
    "def define_generator(latent_dim):\n",
    "\tmodel = Sequential()\n",
    "\t# Define number of nodes that can be gradually reshaped and upscaled to 128x128x3\n",
    "\tn_nodes = 128 * 8 * 8 #8192 nodes\n",
    "\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\tmodel.add(Reshape((8, 8, 128)))\n",
    "\t# upsample to 16x16\n",
    "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# upsample to 32x32\n",
    "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# upsample to 64x64\n",
    "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# upsample to 128x128\n",
    "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# output layer 128x128x3\n",
    "\tmodel.add(Conv2D(3, (8,8), activation='tanh', padding='same')) #tanh goes from [-1,1]\n",
    "\treturn model\n",
    "\n",
    "test_gen = define_generator(100)\n",
    "print(test_gen.summary())\n",
    "plot_model(test_gen,to_file=os.path.join(output_path,'generator_model.png'), show_shapes=True)\n",
    "\n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\td_model.trainable = False\n",
    "\t# connect them\n",
    "\tmodel = Sequential()\n",
    "\t# add generator\n",
    "\tmodel.add(g_model)\n",
    "\t# add the discriminator\n",
    "\tmodel.add(d_model)\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "\treturn model\n",
    "\n",
    "\n",
    "test_gan = define_gan(test_gen, test_discr)\n",
    "print(test_gan.summary())\n",
    "plot_model(test_gan, to_file=os.path.join(output_path,'combined_model.png'), show_shapes=True)\n",
    "\n",
    "\n",
    "# Function to sample some random real images\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "\tix = randint(0, dataset.shape[0], n_samples)\n",
    "\tX = dataset[ix]\n",
    "\ty = np.ones((n_samples, 1)) # Class labels for real images are 1\n",
    "\treturn X, y\n",
    "\n",
    "# Function to generate random latent points\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "\tx_input = randn(latent_dim * n_samples)\n",
    "\tx_input = x_input.reshape(n_samples, latent_dim) #Reshape to be provided as input to the generator. \n",
    "\treturn x_input\n",
    "\n",
    "# Function to generate fake images using latent vectors\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "\tx_input = generate_latent_points(latent_dim, n_samples) #Generate latent points as input to the generator\n",
    "\tX = g_model.predict(x_input) #Use the generator to generate fake images\n",
    "\ty = np.zeros((n_samples, 1)) # Class labels for fake images are 0\n",
    "\treturn X, y\n",
    "\n",
    "# Function to save Plots after every n number of epochs\n",
    "def save_plot(examples, epoch, n=10):\n",
    "\t# scale images from [-1,1] to [0,1] so we can plot\n",
    "\texamples = (examples + 1) / 2.0\n",
    "\tfor i in range(n * n):\n",
    "\t\tplt.subplot(n, n, 1 + i)\n",
    "\t\tplt.axis('off')\n",
    "\t\tplt.imshow(examples[i])\n",
    "\t# save plot to a file so we can view how generated images evolved over epochs\n",
    "\tfname = 'generated_plot_128x128_e%03d.png' % (epoch+1)\n",
    "\tnew_path = os.path.join(output_path,fname)\n",
    "\tplt.savefig(fname)\n",
    "\tplt.close()\n",
    "\n",
    "# Function to summarize performance periodically. \n",
    "# \n",
    "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
    "\t# Fetch real images\n",
    "\tX_real, y_real = generate_real_samples(dataset, n_samples)\n",
    "\t# evaluate discriminator on real images - get accuracy\n",
    "\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
    "\t# Generate fake images\n",
    "\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "\t# evaluate discriminator on fake images - get accuracy\n",
    "\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
    "\t# Print discriminate accuracies on ral and fake images. \n",
    "\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
    "\t# save generated images periodically using the save_plot function\n",
    "\tsave_plot(x_fake, epoch)\n",
    "\t# save the generator model\n",
    "\tfname = 'generator_model_128x128_%03d.h5' % (epoch+1)\n",
    "\tnew_path = os.path.join(output_path,fname)\n",
    "\tg_model.save(new_path)\n",
    "\n",
    "# train the generator and discriminator by enumerating batches and epochs. \n",
    "#\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=epochs, n_batch=batch_size):\n",
    "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "\thalf_batch = int(n_batch / 2) #Disc. trained on half batch real and half batch fake images\n",
    "\t#  enumerate epochs\n",
    "\tfor i in range(n_epochs):\n",
    "\t\t# enumerate batches \n",
    "\t\tfor j in range(bat_per_epo):\n",
    "\t\t\t# Fetch random 'real' images\n",
    "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "\t\t\t# Train the discriminator using real images\n",
    "\t\t\td_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
    "\t\t\t# generate 'fake' images \n",
    "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "\t\t\t# Train the discriminator using fake images\n",
    "\t\t\td_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
    "\t\t\t# Generate latent vectors as input for the generator\n",
    "\t\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
    "\t\t\t# Label generated (fake) mages as 1 to fool the discriminator \n",
    "\t\t\ty_gan = np.ones((n_batch, 1))\n",
    "\t\t\t# Train the generator (via the discriminator's error)\n",
    "\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "\t\t\t# Report disc. and gen losses. \n",
    "\t\t\tprint('Epoch>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
    "\t\t\t\t(i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "\t\t# evaluate the model performance, sometimes\n",
    "\t\tif (i+1) % 10 == 0:\n",
    "\t\t\tsummarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
    "\n",
    "############################################\n",
    "\n",
    "#Rescale to [-1, 1] - remember that the generator uses tanh activation that goes from -1,1\n",
    "# dataset = dataset.astype('float32')\n",
    "\t# scale from [0,255] to [-1,1]\n",
    "# dataset = (dataset - 127.5) / 127.5\n",
    "\n",
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# create the discriminator using our pre-defined function\n",
    "d_model = define_discriminator()\n",
    "# create the generator using our pre-defined function\n",
    "g_model = define_generator(latent_dim)\n",
    "# create the gan  using our pre-defined function\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "\n",
    "# train model\n",
    "train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=epochs)\n",
    "print('TRAIN COMPLETE')\n",
    "# size of the latent space\n",
    "latent_dim = 100\n",
    "# define the discriminator model\n",
    "# generate samples\n",
    "n_samples = 25\n",
    "X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "# plot the generated samples\n",
    "for i in range(n_samples):\n",
    " # define subplot\n",
    " plt.subplot(5, 5, 1 + i)\n",
    " # turn off axis labels\n",
    " plt.axis('off')\n",
    " # plot single image\n",
    " plt.imshow(X[i, :, :, 0])\n",
    "# show the figure\n",
    "plt.savefig('output_example.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738a36c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6492e0e9b8225cbe5f1e140fb4bfe0c629b839b230ee76edc4688c7eb44b2440"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
